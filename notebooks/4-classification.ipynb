{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_19001</th>\n",
       "      <th>vote_19002</th>\n",
       "      <th>vote_19003</th>\n",
       "      <th>vote_19004</th>\n",
       "      <th>vote_19005</th>\n",
       "      <th>vote_19006</th>\n",
       "      <th>vote_19007</th>\n",
       "      <th>vote_19008</th>\n",
       "      <th>vote_19009</th>\n",
       "      <th>vote_19010</th>\n",
       "      <th>...</th>\n",
       "      <th>vote_19236</th>\n",
       "      <th>vote_19237</th>\n",
       "      <th>vote_19238</th>\n",
       "      <th>vote_19239</th>\n",
       "      <th>vote_19240</th>\n",
       "      <th>vote_19241</th>\n",
       "      <th>vote_19242</th>\n",
       "      <th>vote_19243</th>\n",
       "      <th>vote_19244</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CDU/CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_19001  vote_19002  vote_19003  vote_19004  vote_19005  vote_19006  \\\n",
       "0         1.0         1.0         1.0         1.0         1.0         1.0   \n",
       "1         1.0         1.0         1.0         1.0         1.0         1.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         1.0         1.0         1.0         1.0         1.0         1.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   vote_19007  vote_19008  vote_19009  vote_19010  ...  vote_19236  \\\n",
       "0         1.0         1.0         0.0         0.0  ...         1.0   \n",
       "1         1.0         1.0         0.0         0.0  ...         1.0   \n",
       "2         0.0         0.0         1.0         0.0  ...         0.0   \n",
       "3         1.0         1.0         0.0         0.0  ...         1.0   \n",
       "4         0.0         0.0         1.0         0.0  ...         0.0   \n",
       "\n",
       "   vote_19237  vote_19238  vote_19239  vote_19240  vote_19241  vote_19242  \\\n",
       "0         1.0         1.0         1.0         1.0         0.0         1.0   \n",
       "1         1.0         1.0         1.0         1.0         0.0         1.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.5   \n",
       "3         1.0         1.0         1.0         1.0         0.0         1.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.5   \n",
       "\n",
       "   vote_19243  vote_19244    party  \n",
       "0         1.0         1.0  CDU/CSU  \n",
       "1         1.0         1.0      SPD  \n",
       "2         0.0         0.0    Linke  \n",
       "3         1.0         1.0  CDU/CSU  \n",
       "4         0.0         0.0    Linke  \n",
       "\n",
       "[5 rows x 245 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "btvote = pd.read_pickle('../data/btvote_imputed.pkl')\n",
    "btvote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and encode target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataframe in 'data' and 'target'\n",
    "btvote_data = btvote.drop('party', axis=1)\n",
    "btvote_target = btvote['party']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "btvote_target = label_encoder.fit_transform(btvote_target)\n",
    "\n",
    "# Split data into stratified train and test split\n",
    "# train split will be used to find best model setting \n",
    "btvote_data_train, btvote_data_test, btvote_target_train, btvote_target_test = train_test_split(btvote_data, btvote_target, test_size=0.25, random_state=42, shuffle=True, stratify=btvote_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch setup\n",
    "\n",
    "As the data is already imputed and no balancing is needed, we don't need a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# define the scoring function\n",
    "# We use 'macro' as average as we want to evaluate the performance of each class equally, regardless of the class size\n",
    "f1 = make_scorer(f1_score, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "We want to find a baseline for the F1 score in the given problem. A common baseline approach is to predict the most frequent class label in the training set for all test items.\n",
    "In our case this would mean to predict 'CDU/CSU' (most represented party) for all MPs while ignoring their voting behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Baseline: 0.08631009957325746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# We use stratified 10 fold cross validation\n",
    "print('Cross Validated Baseline: {}'.format(cross_val_score(DummyClassifier(strategy=\"most_frequent\"), btvote_data_train, btvote_target_train, cv=stratified_10_fold_cv, scoring=f1).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ranking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>manhattan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.832154</td>\n",
       "      <td>0.825988</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.813371</td>\n",
       "      <td>0.808027</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.865122</td>\n",
       "      <td>0.859869</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.864372</td>\n",
       "      <td>0.859694</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.842799</td>\n",
       "      <td>0.834444</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.829126</td>\n",
       "      <td>0.825144</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.866111</td>\n",
       "      <td>0.863029</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.864153</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.865120</td>\n",
       "      <td>0.862823</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.867272</td>\n",
       "      <td>0.863524</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.863237</td>\n",
       "      <td>0.860205</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.860981</td>\n",
       "      <td>0.857786</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.859590</td>\n",
       "      <td>0.854604</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.859480</td>\n",
       "      <td>0.852322</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>distance</th>\n",
       "      <td>0.856788</td>\n",
       "      <td>0.854837</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>0.852664</td>\n",
       "      <td>0.848482</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean_test_score             ranking          \n",
       "metric                     euclidean manhattan euclidean manhattan\n",
       "n_neighbors weights                                               \n",
       "2           distance        0.832154  0.825988        27        29\n",
       "            uniform         0.813371  0.808027        31        32\n",
       "3           distance        0.865122  0.859869         4        14\n",
       "            uniform         0.864372  0.859694         6        15\n",
       "4           distance        0.842799  0.834444        25        26\n",
       "            uniform         0.829126  0.825144        28        30\n",
       "5           distance        0.866111  0.863029         3        10\n",
       "            uniform         0.868099  0.864153         1         7\n",
       "6           distance        0.865120  0.862823         5        11\n",
       "            uniform         0.867272  0.863524         2         8\n",
       "7           distance        0.863237  0.860205         9        13\n",
       "            uniform         0.860981  0.857786        12        18\n",
       "8           distance        0.859590  0.854604        16        21\n",
       "            uniform         0.859480  0.852322        17        23\n",
       "9           distance        0.856788  0.854837        19        20\n",
       "            uniform         0.852664  0.848482        22        24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': range(2, 10),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # For Minkowski distance (1 for Manhattan, 2 for Euclidean)'\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(KNeighborsClassifier(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['n_neighbors'] = results['param_n_neighbors'].astype(str)\n",
    "results['weights'] = results['param_weights'].astype(str)\n",
    "results['metric'] = results['param_p'].replace({1:'manhattan', 2:'euclidean'})\n",
    "results['ranking'] = results['rank_test_score'].astype(int)\n",
    "pivoted_results = results.pivot(index=['n_neighbors','weights'], columns='metric', values=['mean_test_score', 'ranking'])\n",
    "pivoted_results['ranking'] = pivoted_results['ranking'].astype(int)\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using distance based weights doesn't always perform better than uniform weights. The euclidean distance generally performs as least as good as manhattan distance.\n",
    "\n",
    "The best parameter setting for the k-NN is n_neighbors=5, distance='euclidean' (p=2), and weights='uniform', which are all default values. The F1 score is 0.868."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.811641</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.855236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  mean_test_score  ranking\n",
       "0  manhattan         0.811641        2\n",
       "1  euclidean         0.855236        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(NearestCentroid(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['metric'] = results['param_metric']\n",
    "results['ranking'] = results['rank_test_score']\n",
    "display(results[['metric','mean_test_score','ranking']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, using euclidean distance performs better than manhattan distance.\n",
    "\n",
    "The best parameter setting for the Nearest Centroid is metric='euclidean', which is the default value. The F1 score is 0.855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogra\\AppData\\Local\\Temp\\ipykernel_32776\\2065465406.py:24: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  pivoted_results = results.pivot(index=['criterion','max_depth'], columns='min_samples_split', values='mean_test_score')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">entropy</th>\n",
       "      <th>10</th>\n",
       "      <td>0.840985</td>\n",
       "      <td>0.840675</td>\n",
       "      <td>0.839816</td>\n",
       "      <td>0.840492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.843407</td>\n",
       "      <td>0.840687</td>\n",
       "      <td>0.843008</td>\n",
       "      <td>0.842367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.830246</td>\n",
       "      <td>0.830246</td>\n",
       "      <td>0.830246</td>\n",
       "      <td>0.830246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.858128</td>\n",
       "      <td>0.851267</td>\n",
       "      <td>0.852138</td>\n",
       "      <td>0.853844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gini</th>\n",
       "      <th>10</th>\n",
       "      <td>0.857728</td>\n",
       "      <td>0.855738</td>\n",
       "      <td>0.853554</td>\n",
       "      <td>0.855673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.860620</td>\n",
       "      <td>0.856683</td>\n",
       "      <td>0.856864</td>\n",
       "      <td>0.858056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.838543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.860279</td>\n",
       "      <td>0.860622</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.859998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <th></th>\n",
       "      <td>0.848742</td>\n",
       "      <td>0.846808</td>\n",
       "      <td>0.846658</td>\n",
       "      <td>0.847403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "min_samples_split           2         5        10   Average\n",
       "criterion max_depth                                        \n",
       "entropy   10         0.840985  0.840675  0.839816  0.840492\n",
       "          15         0.843407  0.840687  0.843008  0.842367\n",
       "          5          0.830246  0.830246  0.830246  0.830246\n",
       "          None       0.858128  0.851267  0.852138  0.853844\n",
       "gini      10         0.857728  0.855738  0.853554  0.855673\n",
       "          15         0.860620  0.856683  0.856864  0.858056\n",
       "          5          0.838543  0.838543  0.838543  0.838543\n",
       "          None       0.860279  0.860622  0.859093  0.859998\n",
       "Average              0.848742  0.846808  0.846658  0.847403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(DecisionTreeClassifier(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['criterion'] = results['param_criterion'].astype(str)\n",
    "results['max_depth'] = results['param_max_depth'].astype(str)\n",
    "results['min_samples_split'] = results['param_min_samples_split']\n",
    "pivoted_results = results.pivot(index=['criterion','max_depth'], columns='min_samples_split', values='mean_test_score')\n",
    "pivoted_results['Average'] = pivoted_results.mean(axis=1)\n",
    "pivoted_results.loc[('Average',''),:] = pivoted_results.mean()\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- max_depth: choosing a max_depth of 5 and 10 works not as good as 15. For 15 and None, the results are similar.\n",
    "- min_samples_split: On average, there are no real differences, 2 works slightly better.\n",
    "- criterion: For a larger max_depth, the top values can be achieved for using gini.\n",
    "\n",
    "We choose criterion='gini' (default), max_depth=15 and min_samples_split=2 (default) as the best parameter setting for a DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaÃ¯ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 score: 0.8350390681618751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "print('Cross-validated F1 score: {}'.format(cross_val_score(model, btvote_data_train, btvote_target_train, scoring=f1, cv=stratified_10_fold_cv).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interim conclusion\n",
    "\n",
    "Up until now, we considered the models, that have been dealt with in detail in the lecture.\n",
    "\n",
    "F1 score of the best parameter setting for each model: \n",
    "- k-NN: 0.868\n",
    "- Nearest Centroid: 0.855\n",
    "- Decision Tree: 0.861\n",
    "- NaÃ¯ve Bayes: 0.835\n",
    "\n",
    "Out of these four models, the k-NN performs the best with the Decision Tree close behind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogra\\AppData\\Local\\Temp\\ipykernel_32776\\1887420654.py:23: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  pivoted_results = results.pivot(index='hidden_layer_sizes', columns='alpha', values='mean_test_score')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alpha</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(100, 50, 25)</th>\n",
       "      <td>0.839571</td>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.838751</td>\n",
       "      <td>0.844149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(100, 50, 25, 10)</th>\n",
       "      <td>0.834268</td>\n",
       "      <td>0.831551</td>\n",
       "      <td>0.837471</td>\n",
       "      <td>0.834430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(50, 50)</th>\n",
       "      <td>0.838726</td>\n",
       "      <td>0.846005</td>\n",
       "      <td>0.842916</td>\n",
       "      <td>0.842549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.845233</td>\n",
       "      <td>0.849892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.841336</td>\n",
       "      <td>0.845837</td>\n",
       "      <td>0.841093</td>\n",
       "      <td>0.842755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha                 0.0001     0.001      0.01   Average\n",
       "hidden_layer_sizes                                        \n",
       "(100, 50, 25)       0.839571  0.854125  0.838751  0.844149\n",
       "(100, 50, 25, 10)   0.834268  0.831551  0.837471  0.834430\n",
       "(50, 50)            0.838726  0.846005  0.842916  0.842549\n",
       "50                  0.852778  0.851667  0.845233  0.849892\n",
       "Average             0.841336  0.845837  0.841093  0.842755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50), (50, 50), (100, 50, 25), (100, 50, 25, 10)], # Specify the architecture of hidden layers\n",
    "    'alpha': [0.0001, 0.001, 0.01], # L2 regularization term\n",
    "    'max_iter': [300], # Increase number of gradient steps so that all combinations convert\n",
    "    'random_state': [42],  # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(MLPClassifier(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['hidden_layer_sizes'] = results['param_hidden_layer_sizes'].astype(str)\n",
    "results['alpha'] = results['param_alpha']\n",
    "pivoted_results = results.pivot(index='hidden_layer_sizes', columns='alpha', values='mean_test_score')\n",
    "pivoted_results['Average'] = pivoted_results.mean(axis=1)\n",
    "pivoted_results.loc['Average',:] = pivoted_results.mean()\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more hidden layers doesn't lead to a higher F1 score. The best results can be achieved for a single hidden layer of size 50. In that case, the alpha parameter 0.0001 produces the best result.\n",
    "\n",
    "The best parameter setting for the MLPClassifier is hidden_layer_sizes=(50), alpha=0.0001, max_iter=300. The F1 score is 0.853."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogra\\AppData\\Local\\Temp\\ipykernel_32776\\2151437375.py:22: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  pivoted_results = results.pivot(index='criterion', columns='n_estimators', values='mean_test_score')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_estimators</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criterion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.853252</td>\n",
       "      <td>0.858115</td>\n",
       "      <td>0.861708</td>\n",
       "      <td>0.868856</td>\n",
       "      <td>0.868562</td>\n",
       "      <td>0.862098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gini</th>\n",
       "      <td>0.855685</td>\n",
       "      <td>0.859381</td>\n",
       "      <td>0.858115</td>\n",
       "      <td>0.867589</td>\n",
       "      <td>0.867589</td>\n",
       "      <td>0.861672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.854468</td>\n",
       "      <td>0.858748</td>\n",
       "      <td>0.859911</td>\n",
       "      <td>0.868223</td>\n",
       "      <td>0.868076</td>\n",
       "      <td>0.861885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_estimators        10        50       100       150       200   Average\n",
       "criterion                                                               \n",
       "entropy       0.853252  0.858115  0.861708  0.868856  0.868562  0.862098\n",
       "gini          0.855685  0.859381  0.858115  0.867589  0.867589  0.861672\n",
       "Average       0.854468  0.858748  0.859911  0.868223  0.868076  0.861885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    'n_estimators': [10, 50, 100, 150, 200],  # Number of trees in the forest\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(RandomForestClassifier(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['criterion'] = results['param_criterion'].astype(str)\n",
    "results['n_estimators'] = results['param_n_estimators']\n",
    "pivoted_results = results.pivot(index='criterion', columns='n_estimators', values='mean_test_score')\n",
    "pivoted_results['Average'] = pivoted_results.mean(axis=1)\n",
    "pivoted_results.loc['Average',:] = pivoted_results.mean()\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterion doesn't significantly affect the result. The maximum F1 score can be achieved using n_estimators=150. We take the combination ('entropy', 150) as it has best result. Now, we will use this pair to evaluate the effect of max_depth and min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogra\\AppData\\Local\\Temp\\ipykernel_32776\\2720907532.py:22: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  pivoted_results = results.pivot(index='max_depth', columns='min_samples_split', values='mean_test_score')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>min_samples_split</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.868856</td>\n",
       "      <td>0.862957</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>0.865933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.829981</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.830120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.840719</td>\n",
       "      <td>0.839311</td>\n",
       "      <td>0.842574</td>\n",
       "      <td>0.840868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.860912</td>\n",
       "      <td>0.857881</td>\n",
       "      <td>0.859279</td>\n",
       "      <td>0.859357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>0.867589</td>\n",
       "      <td>0.862957</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>0.865511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>0.868856</td>\n",
       "      <td>0.862957</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>0.865933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.0</th>\n",
       "      <td>0.868856</td>\n",
       "      <td>0.862957</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>0.865933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.857997</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>0.856570</td>\n",
       "      <td>0.856237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "min_samples_split         2         5        10   Average\n",
       "max_depth                                                \n",
       "NaN                0.868856  0.862957  0.865987  0.865933\n",
       "10.0               0.830189  0.829981  0.830189  0.830120\n",
       "20.0               0.840719  0.839311  0.842574  0.840868\n",
       "30.0               0.860912  0.857881  0.859279  0.859357\n",
       "40.0               0.867589  0.862957  0.865987  0.865511\n",
       "50.0               0.868856  0.862957  0.865987  0.865933\n",
       "60.0               0.868856  0.862957  0.865987  0.865933\n",
       "Average            0.857997  0.854143  0.856570  0.856237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set parameter grid\n",
    "parameters = {\n",
    "    'criterion': ['entropy'],\n",
    "    'n_estimators': [150],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50, 60],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(RandomForestClassifier(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "\n",
    "# transform the results for better visualization\n",
    "results['max_depth'] = results['param_max_depth']\n",
    "results['min_samples_split'] = results['param_min_samples_split']\n",
    "pivoted_results = results.pivot(index='max_depth', columns='min_samples_split', values='mean_test_score')\n",
    "pivoted_results['Average'] = pivoted_results.mean(axis=1)\n",
    "pivoted_results.loc['Average',:] = pivoted_results.mean()\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default min_samples_split value 2 performs the best. A max_depth of 50 maximizes the F1 score.\n",
    "\n",
    "Finally the best parameter setting for the Random Forest classifier is criterion='entropy', n_estimators=150, max_depth=50, and min_samples_split=2 (default). The F1 score is 0.869."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mogra\\AppData\\Local\\Temp\\ipykernel_32776\\4210631860.py:22: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  pivoted_results = results.pivot(index=['kernel','gamma'], columns='C', values='mean_test_score')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "      <th>50.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel</th>\n",
       "      <th>gamma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">linear</th>\n",
       "      <th>auto</th>\n",
       "      <td>0.806992</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836889</td>\n",
       "      <td>0.835384</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.838727</td>\n",
       "      <td>0.832531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale</th>\n",
       "      <td>0.806992</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836889</td>\n",
       "      <td>0.835384</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.838727</td>\n",
       "      <td>0.832531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rbf</th>\n",
       "      <th>auto</th>\n",
       "      <td>0.785385</td>\n",
       "      <td>0.788182</td>\n",
       "      <td>0.804363</td>\n",
       "      <td>0.812282</td>\n",
       "      <td>0.826384</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.808783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale</th>\n",
       "      <td>0.788182</td>\n",
       "      <td>0.793832</td>\n",
       "      <td>0.815466</td>\n",
       "      <td>0.828984</td>\n",
       "      <td>0.834704</td>\n",
       "      <td>0.836201</td>\n",
       "      <td>0.816228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <th></th>\n",
       "      <td>0.796888</td>\n",
       "      <td>0.813554</td>\n",
       "      <td>0.823402</td>\n",
       "      <td>0.828008</td>\n",
       "      <td>0.835818</td>\n",
       "      <td>0.837439</td>\n",
       "      <td>0.822518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C                   0.1       1.0      10.0      20.0      50.0     100.0  \\\n",
       "kernel  gamma                                                               \n",
       "linear  auto   0.806992  0.836101  0.836889  0.835384  0.841091  0.838727   \n",
       "        scale  0.806992  0.836101  0.836889  0.835384  0.841091  0.838727   \n",
       "rbf     auto   0.785385  0.788182  0.804363  0.812282  0.826384  0.836101   \n",
       "        scale  0.788182  0.793832  0.815466  0.828984  0.834704  0.836201   \n",
       "Average        0.796888  0.813554  0.823402  0.828008  0.835818  0.837439   \n",
       "\n",
       "C               Average  \n",
       "kernel  gamma            \n",
       "linear  auto   0.832531  \n",
       "        scale  0.832531  \n",
       "rbf     auto   0.808783  \n",
       "        scale  0.816228  \n",
       "Average        0.822518  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# set parameter grid\n",
    "parameters = {\n",
    "    'C': [0.1, 1.0, 10, 20, 50, 100], # regularization parameter\n",
    "    'kernel': ['linear', 'rbf'], # kernel type used in the algorithm\n",
    "    'gamma': ['scale', 'auto'], # kernel coefficient parameter for 'rbf'\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(SVC(), parameters, scoring=f1, cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "results['kernel'] = results['param_kernel'].astype(str)\n",
    "results['gamma'] = results['param_gamma'].astype(str)\n",
    "results['C'] = results['param_C']\n",
    "pivoted_results = results.pivot(index=['kernel','gamma'], columns='C', values='mean_test_score')\n",
    "pivoted_results['Average'] = pivoted_results.mean(axis=1)\n",
    "pivoted_results.loc[('Average',''),:] = pivoted_results.mean()\n",
    "display(pivoted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a linear kernel performs significantly better than the rbf kernel. In that case the gamma parameter is irrelevant. The F1 score reaches its maximum with C=50.\n",
    "\n",
    "The best parameter setting for SVM is kernel='linear', C=50. The F1 score is 0.841."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Finally, we compare the k-NN with the three alternative approaches.\n",
    "\n",
    "F1 score of the best parameter setting for each model: \n",
    "- k-NN: 0.868\n",
    "- Neural Network: 0.853\n",
    "- Random Forest: 0.869\n",
    "- Support Vector Machine: 0.841\n",
    "\n",
    "Out of these four models, the k-NN and the Random Forest perform approximately equally good.\n",
    "\n",
    "The k-NN model has the advantage in terms of simplicity and interpretability. Since the performance is equally good for both models, Occam's Razor favors the simpler one of the two, which is the k-NN. Nevertheless, when selecting the features in the next notebook, we will once again consider the Random Forest classifier as an option.\n",
    "\n",
    "We finally declare k-NN with n_neighbors=5, distance='euclidean' (p=2), and weights='uniform' (all default values) as the best model for our classification task.\n",
    "\n",
    "We further evaluate this model on unseen data using the test set, we generated before performing the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further k-NN evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.75      0.45      0.57        66\n",
      "           2       1.00      0.95      0.98        21\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        18\n",
      "           5       0.46      0.76      0.57        41\n",
      "\n",
      "    accuracy                           0.75       187\n",
      "   macro avg       0.87      0.86      0.85       187\n",
      "weighted avg       0.79      0.75      0.75       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define the best model again\n",
    "best_model = KNeighborsClassifier()\n",
    "\n",
    "# fit model on training data\n",
    "best_model.fit(btvote_data_train, btvote_target_train)\n",
    "\n",
    "# get predictions for test data\n",
    "prediction = best_model.predict(btvote_data_test)\n",
    "\n",
    "# generate classification report from predictions\n",
    "print(classification_report(btvote_target_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores on our test data are:\n",
    "- accuracy: 0.75\n",
    "- macro precision: 0.87\n",
    "- macro recall: 0.86\n",
    "- macro F1 score: 0.85\n",
    "\n",
    "The only classes with significant performance issues are 1 (CDU/CSU) and 5 (SPD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x261d20ee380>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix(btvote_target_test, prediction), display_labels=label_encoder.classes_).plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix validates, that most of the false predictions result from errors between CDU/CSU and SPD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For six random train/test examples, we see that the difficulty always lies with differentiating between CDU/CDU and SPD. Sometimes more SPD MPs are classified as CDU/CSU, sometimes the other way around."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
